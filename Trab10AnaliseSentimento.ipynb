{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.classify import PositiveNaiveBayesClassifier\n",
    "from nltk.tokenize import word_tokenize # or use some other tokenizer\n",
    "from nltk.metrics import *\n",
    "\n",
    "\n",
    "\n",
    "print(\"Aguarde...\\n\")\n",
    "\n",
    "neg = []\n",
    "pos = []\n",
    "neg_set = []\n",
    "pos_set = []\n",
    "\n",
    "def negative():\n",
    "    arq = open('neg_tweets.txt', 'r',-1,'utf-8')\n",
    "    texto = \"\"\n",
    "    texto = arq.readlines()\n",
    "    texto = texto[:80]\n",
    "    global neg\n",
    "    global neg_set\n",
    "    for i in texto:\n",
    "        neg.append((str(i),'neg'))\n",
    "        neg_set.append((str(i),'pos'))\n",
    "\n",
    "\n",
    "    all_words = set(word.lower() for passage in neg for word in word_tokenize(passage[0]))\n",
    "    neg = [({word: (word in word_tokenize(x[0])) for word in all_words}, x[1]) for x in neg]\n",
    "    return neg\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def positive():\n",
    "    arq2 = open('pos_tweets.txt', 'r',-1,'utf-8')\n",
    "    texto = \"\"\n",
    "    texto = arq2.readlines()\n",
    "    texto = texto[:80]\n",
    "    global pos\n",
    "    global pos_set\n",
    "    for i in texto:\n",
    "        pos.append((str(i),'pos'))\n",
    "        pos_set.append((str(i),'pos'))\n",
    "\n",
    "    all_words = set(word.lower() for passage in pos for word in word_tokenize(passage[0]))\n",
    "    pos = [({word: (word in word_tokenize(x[0])) for word in all_words}, x[1]) for x in pos]\n",
    "    return pos\n",
    "\n",
    "def precision(reference, test):\n",
    "    \"\"\"\n",
    "    Given a set of reference values and a set of test values, return\n",
    "    the fraction of test values that appear in the reference set.\n",
    "    In particular, return card(``reference`` intersection ``test``)/card(``test``).\n",
    "    If ``test`` is empty, then return None.\n",
    "\n",
    "    :type reference: set\n",
    "    :param reference: A set of reference values.\n",
    "    :type test: set\n",
    "    :param test: A set of values to compare against the reference set.\n",
    "    :rtype: float or None\n",
    "    \"\"\"\n",
    "    if not hasattr(reference, 'intersection') or not hasattr(test, 'intersection'):\n",
    "        raise TypeError('reference and test should be sets')\n",
    "\n",
    "    if len(test) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return len(reference.intersection(test)) / len(test)\n",
    "\n",
    "\n",
    "\n",
    "def recall(reference, test):\n",
    "    \"\"\"\n",
    "    Given a set of reference values and a set of test values, return\n",
    "    the fraction of reference values that appear in the test set.\n",
    "    In particular, return card(``reference`` intersection ``test``)/card(``reference``).\n",
    "    If ``reference`` is empty, then return None.\n",
    "\n",
    "    :type reference: set\n",
    "    :param reference: A set of reference values.\n",
    "    :type test: set\n",
    "    :param test: A set of values to compare against the reference set.\n",
    "    :rtype: float or None\n",
    "    \"\"\"\n",
    "    if not hasattr(reference, 'intersection') or not hasattr(test, 'intersection'):\n",
    "        raise TypeError('reference and test should be sets')\n",
    "\n",
    "    if len(reference) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return len(reference.intersection(test)) / len(reference)\n",
    "\n",
    "\n",
    "\n",
    "def f_measure(reference, test, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Given a set of reference values and a set of test values, return\n",
    "    the f-measure of the test values, when compared against the\n",
    "    reference values.  The f-measure is the harmonic mean of the\n",
    "    ``precision`` and ``recall``, weighted by ``alpha``.  In particular,\n",
    "    given the precision *p* and recall *r* defined by:\n",
    "\n",
    "    - *p* = card(``reference`` intersection ``test``)/card(``test``)\n",
    "    - *r* = card(``reference`` intersection ``test``)/card(``reference``)\n",
    "\n",
    "    The f-measure is:\n",
    "\n",
    "    - *1/(alpha/p + (1-alpha)/r)*\n",
    "\n",
    "    If either ``reference`` or ``test`` is empty, then ``f_measure``\n",
    "    returns None.\n",
    "\n",
    "    :type reference: set\n",
    "    :param reference: A set of reference values.\n",
    "    :type test: set\n",
    "    :param test: A set of values to compare against the reference set.\n",
    "    :rtype: float or None\n",
    "    \"\"\"\n",
    "    p = precision(reference, test)\n",
    "    r = recall(reference, test)\n",
    "    if p is None or r is None:\n",
    "        return None\n",
    "    if p == 0 or r == 0:\n",
    "        return 0\n",
    "    return 1.0 / (alpha / p + (1 - alpha) / r)\n",
    "\n",
    "negative()\n",
    "positive()\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(neg[:39]+pos[:39])\n",
    "print(\"Classifier accuracy percent:\",(nltk.classify.accuracy(classifier, neg[40:]+pos[40:]))*100)\n",
    "reference = set(neg_set[:39]+pos_set[:39])\n",
    "test = set(neg_set[40:]+pos_set[40:])\n",
    "print(\"Classifier F1 percent:\",(f_measure(reference, test)))\n",
    "classifier.show_most_informative_features(10)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
